{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03: Experiment Management\n",
    "\n",
    "## What you will learn\n",
    "\n",
    "- How experiment management brings observability to ML model development\n",
    "- Workflows for using MLFlow in experiment management, including metric logging, artifact versioning, and hyperparameter optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Management with MLFLow\n",
    "\n",
    "We will be using MLflow Tracking for experiment management. The MLflow Tracking is an API and UI for logging parameters, code versions, metrics, and output files when running your machine learning code and for later visualizing the results.\n",
    "\n",
    "There are two important concepts:\n",
    "\n",
    "- **Runs**: Runs are executions of some piece of data science code (e.g. `python train.py`). Each run records metadata (metrics, parameters, start and end times) and as well as the artifacts produced by the code (e.g. model weights).\n",
    "- **Experiments**: An experiment groups together runs for a specific task.\n",
    "\n",
    "### Tracking experiments with MLFlow\n",
    "\n",
    "Let's start a local instance of MLFLow (run this in a terminal):\n",
    "\n",
    "```shell\n",
    "mlflow server --host 127.0.0.1 --port 8080\n",
    "```\n",
    "\n",
    "This will start an MLFlow tracking server, its UI and all the other necessary components. Use your browser to navigate to `localhost:8080`. You should be presented with a page that looks like the one in the screenshot below:\n",
    "\n",
    "![Image]()\n",
    "\n",
    "As you can see, there are two tabs: one for experiments and one for models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autologging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn: A little Hyperparameter-Tuning Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-lab-03",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
